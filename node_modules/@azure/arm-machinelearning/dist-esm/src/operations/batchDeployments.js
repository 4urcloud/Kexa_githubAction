/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
import { __asyncDelegator, __asyncGenerator, __asyncValues, __await, __awaiter } from "tslib";
import { setContinuationToken } from "../pagingHelper";
import * as coreClient from "@azure/core-client";
import * as Mappers from "../models/mappers";
import * as Parameters from "../models/parameters";
import { LroEngine } from "@azure/core-lro";
import { LroImpl } from "../lroImpl";
/// <reference lib="esnext.asynciterable" />
/** Class containing BatchDeployments operations. */
export class BatchDeploymentsImpl {
    /**
     * Initialize a new instance of the class BatchDeployments class.
     * @param client Reference to the service client
     */
    constructor(client) {
        this.client = client;
    }
    /**
     * Lists Batch inference deployments in the workspace.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param options The options parameters.
     */
    list(resourceGroupName, workspaceName, endpointName, options) {
        const iter = this.listPagingAll(resourceGroupName, workspaceName, endpointName, options);
        return {
            next() {
                return iter.next();
            },
            [Symbol.asyncIterator]() {
                return this;
            },
            byPage: (settings) => {
                if (settings === null || settings === void 0 ? void 0 : settings.maxPageSize) {
                    throw new Error("maxPageSize is not supported by this operation.");
                }
                return this.listPagingPage(resourceGroupName, workspaceName, endpointName, options, settings);
            }
        };
    }
    listPagingPage(resourceGroupName, workspaceName, endpointName, options, settings) {
        return __asyncGenerator(this, arguments, function* listPagingPage_1() {
            let result;
            let continuationToken = settings === null || settings === void 0 ? void 0 : settings.continuationToken;
            if (!continuationToken) {
                result = yield __await(this._list(resourceGroupName, workspaceName, endpointName, options));
                let page = result.value || [];
                continuationToken = result.nextLink;
                setContinuationToken(page, continuationToken);
                yield yield __await(page);
            }
            while (continuationToken) {
                result = yield __await(this._listNext(resourceGroupName, workspaceName, endpointName, continuationToken, options));
                continuationToken = result.nextLink;
                let page = result.value || [];
                setContinuationToken(page, continuationToken);
                yield yield __await(page);
            }
        });
    }
    listPagingAll(resourceGroupName, workspaceName, endpointName, options) {
        return __asyncGenerator(this, arguments, function* listPagingAll_1() {
            var e_1, _a;
            try {
                for (var _b = __asyncValues(this.listPagingPage(resourceGroupName, workspaceName, endpointName, options)), _c; _c = yield __await(_b.next()), !_c.done;) {
                    const page = _c.value;
                    yield __await(yield* __asyncDelegator(__asyncValues(page)));
                }
            }
            catch (e_1_1) { e_1 = { error: e_1_1 }; }
            finally {
                try {
                    if (_c && !_c.done && (_a = _b.return)) yield __await(_a.call(_b));
                }
                finally { if (e_1) throw e_1.error; }
            }
        });
    }
    /**
     * Lists Batch inference deployments in the workspace.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param options The options parameters.
     */
    _list(resourceGroupName, workspaceName, endpointName, options) {
        return this.client.sendOperationRequest({ resourceGroupName, workspaceName, endpointName, options }, listOperationSpec);
    }
    /**
     * Delete Batch Inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param deploymentName Inference deployment identifier.
     * @param options The options parameters.
     */
    beginDelete(resourceGroupName, workspaceName, endpointName, deploymentName, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const directSendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                return this.client.sendOperationRequest(args, spec);
            });
            const sendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                var _a;
                let currentRawResponse = undefined;
                const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
                const callback = (rawResponse, flatResponse) => {
                    currentRawResponse = rawResponse;
                    providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
                };
                const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
                const flatResponse = yield directSendOperation(updatedArgs, spec);
                return {
                    flatResponse,
                    rawResponse: {
                        statusCode: currentRawResponse.status,
                        body: currentRawResponse.parsedBody,
                        headers: currentRawResponse.headers.toJSON()
                    }
                };
            });
            const lro = new LroImpl(sendOperation, {
                resourceGroupName,
                workspaceName,
                endpointName,
                deploymentName,
                options
            }, deleteOperationSpec);
            const poller = new LroEngine(lro, {
                resumeFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
                intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs
            });
            yield poller.poll();
            return poller;
        });
    }
    /**
     * Delete Batch Inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param deploymentName Inference deployment identifier.
     * @param options The options parameters.
     */
    beginDeleteAndWait(resourceGroupName, workspaceName, endpointName, deploymentName, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const poller = yield this.beginDelete(resourceGroupName, workspaceName, endpointName, deploymentName, options);
            return poller.pollUntilDone();
        });
    }
    /**
     * Gets a batch inference deployment by id.
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param deploymentName The identifier for the Batch deployments.
     * @param options The options parameters.
     */
    get(resourceGroupName, workspaceName, endpointName, deploymentName, options) {
        return this.client.sendOperationRequest({
            resourceGroupName,
            workspaceName,
            endpointName,
            deploymentName,
            options
        }, getOperationSpec);
    }
    /**
     * Update a batch inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Inference endpoint name
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param body Batch inference deployment definition object.
     * @param options The options parameters.
     */
    beginUpdate(resourceGroupName, workspaceName, endpointName, deploymentName, body, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const directSendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                return this.client.sendOperationRequest(args, spec);
            });
            const sendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                var _a;
                let currentRawResponse = undefined;
                const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
                const callback = (rawResponse, flatResponse) => {
                    currentRawResponse = rawResponse;
                    providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
                };
                const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
                const flatResponse = yield directSendOperation(updatedArgs, spec);
                return {
                    flatResponse,
                    rawResponse: {
                        statusCode: currentRawResponse.status,
                        body: currentRawResponse.parsedBody,
                        headers: currentRawResponse.headers.toJSON()
                    }
                };
            });
            const lro = new LroImpl(sendOperation, {
                resourceGroupName,
                workspaceName,
                endpointName,
                deploymentName,
                body,
                options
            }, updateOperationSpec);
            const poller = new LroEngine(lro, {
                resumeFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
                intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs
            });
            yield poller.poll();
            return poller;
        });
    }
    /**
     * Update a batch inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Inference endpoint name
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param body Batch inference deployment definition object.
     * @param options The options parameters.
     */
    beginUpdateAndWait(resourceGroupName, workspaceName, endpointName, deploymentName, body, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const poller = yield this.beginUpdate(resourceGroupName, workspaceName, endpointName, deploymentName, body, options);
            return poller.pollUntilDone();
        });
    }
    /**
     * Creates/updates a batch inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Inference endpoint name
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param body Batch inference deployment definition object.
     * @param options The options parameters.
     */
    beginCreateOrUpdate(resourceGroupName, workspaceName, endpointName, deploymentName, body, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const directSendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                return this.client.sendOperationRequest(args, spec);
            });
            const sendOperation = (args, spec) => __awaiter(this, void 0, void 0, function* () {
                var _a;
                let currentRawResponse = undefined;
                const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
                const callback = (rawResponse, flatResponse) => {
                    currentRawResponse = rawResponse;
                    providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
                };
                const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
                const flatResponse = yield directSendOperation(updatedArgs, spec);
                return {
                    flatResponse,
                    rawResponse: {
                        statusCode: currentRawResponse.status,
                        body: currentRawResponse.parsedBody,
                        headers: currentRawResponse.headers.toJSON()
                    }
                };
            });
            const lro = new LroImpl(sendOperation, {
                resourceGroupName,
                workspaceName,
                endpointName,
                deploymentName,
                body,
                options
            }, createOrUpdateOperationSpec);
            const poller = new LroEngine(lro, {
                resumeFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
                intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs
            });
            yield poller.poll();
            return poller;
        });
    }
    /**
     * Creates/updates a batch inference deployment (asynchronous).
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Inference endpoint name
     * @param deploymentName The identifier for the Batch inference deployment.
     * @param body Batch inference deployment definition object.
     * @param options The options parameters.
     */
    beginCreateOrUpdateAndWait(resourceGroupName, workspaceName, endpointName, deploymentName, body, options) {
        return __awaiter(this, void 0, void 0, function* () {
            const poller = yield this.beginCreateOrUpdate(resourceGroupName, workspaceName, endpointName, deploymentName, body, options);
            return poller.pollUntilDone();
        });
    }
    /**
     * ListNext
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param endpointName Endpoint name
     * @param nextLink The nextLink from the previous successful call to the List method.
     * @param options The options parameters.
     */
    _listNext(resourceGroupName, workspaceName, endpointName, nextLink, options) {
        return this.client.sendOperationRequest({ resourceGroupName, workspaceName, endpointName, nextLink, options }, listNextOperationSpec);
    }
}
// Operation Specifications
const serializer = coreClient.createSerializer(Mappers, /* isXml */ false);
const listOperationSpec = {
    path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/batchEndpoints/{endpointName}/deployments",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.BatchDeploymentTrackedResourceArmPaginatedResult
        },
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    queryParameters: [
        Parameters.apiVersion,
        Parameters.skip,
        Parameters.orderBy,
        Parameters.top
    ],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.endpointName
    ],
    headerParameters: [Parameters.accept],
    serializer
};
const deleteOperationSpec = {
    path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/batchEndpoints/{endpointName}/deployments/{deploymentName}",
    httpMethod: "DELETE",
    responses: {
        200: {},
        201: {},
        202: {},
        204: {},
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    queryParameters: [Parameters.apiVersion],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.endpointName,
        Parameters.deploymentName
    ],
    headerParameters: [Parameters.accept],
    serializer
};
const getOperationSpec = {
    path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/batchEndpoints/{endpointName}/deployments/{deploymentName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.BatchDeployment
        },
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    queryParameters: [Parameters.apiVersion],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.endpointName,
        Parameters.deploymentName
    ],
    headerParameters: [Parameters.accept],
    serializer
};
const updateOperationSpec = {
    path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/batchEndpoints/{endpointName}/deployments/{deploymentName}",
    httpMethod: "PATCH",
    responses: {
        200: {
            bodyMapper: Mappers.BatchDeployment
        },
        201: {
            bodyMapper: Mappers.BatchDeployment
        },
        202: {
            bodyMapper: Mappers.BatchDeployment
        },
        204: {
            bodyMapper: Mappers.BatchDeployment
        },
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    requestBody: Parameters.body2,
    queryParameters: [Parameters.apiVersion],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.endpointName1,
        Parameters.deploymentName1
    ],
    headerParameters: [Parameters.accept, Parameters.contentType],
    mediaType: "json",
    serializer
};
const createOrUpdateOperationSpec = {
    path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/batchEndpoints/{endpointName}/deployments/{deploymentName}",
    httpMethod: "PUT",
    responses: {
        200: {
            bodyMapper: Mappers.BatchDeployment
        },
        201: {
            bodyMapper: Mappers.BatchDeployment
        },
        202: {
            bodyMapper: Mappers.BatchDeployment
        },
        204: {
            bodyMapper: Mappers.BatchDeployment
        },
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    requestBody: Parameters.body3,
    queryParameters: [Parameters.apiVersion],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.endpointName1,
        Parameters.deploymentName1
    ],
    headerParameters: [Parameters.accept, Parameters.contentType],
    mediaType: "json",
    serializer
};
const listNextOperationSpec = {
    path: "{nextLink}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.BatchDeploymentTrackedResourceArmPaginatedResult
        },
        default: {
            bodyMapper: Mappers.ErrorResponse
        }
    },
    queryParameters: [
        Parameters.apiVersion,
        Parameters.skip,
        Parameters.orderBy,
        Parameters.top
    ],
    urlParameters: [
        Parameters.$host,
        Parameters.subscriptionId,
        Parameters.resourceGroupName,
        Parameters.workspaceName,
        Parameters.nextLink,
        Parameters.endpointName
    ],
    headerParameters: [Parameters.accept],
    serializer
};
//# sourceMappingURL=batchDeployments.js.map